{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import databento as db\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ts_event  ofi_integrated\n",
      "0 2024-12-03 09:00:00.035672616+00:00       -1.777603\n",
      "1 2024-12-03 09:00:00.121915651+00:00        3.400511\n",
      "2 2024-12-03 09:00:00.121932046+00:00        0.233129\n",
      "3 2024-12-03 09:00:00.122328825+00:00       -3.400510\n",
      "4 2024-12-03 09:00:00.122343653+00:00        3.400511\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/XNAS-20250103-FR8JNPNEEV/xnas-itch-20241203.mbp-10.dbn.zst\"\n",
    "data = db.DBNStore.from_file(file_path)\n",
    "df = data.to_df()\n",
    "\n",
    "filtered_df = df[(df['depth'] >= 0) & (df['depth'] <= 4)]\n",
    "\n",
    "# Step 2: Retain only specific columns\n",
    "columns_to_keep = [\n",
    "    'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', \n",
    "    'bid_ct_00', 'ask_ct_00', 'ts_event', 'bid_px_01', 'ask_px_01', 'bid_sz_01', 'ask_sz_01', \n",
    "    'bid_ct_01', 'ask_ct_01', 'bid_px_02', 'ask_px_02', 'bid_sz_02', 'ask_sz_02', \n",
    "    'bid_ct_02', 'ask_ct_02', 'bid_px_03', 'ask_px_03', 'bid_sz_03', 'ask_sz_03', \n",
    "    'bid_ct_03', 'ask_ct_03', 'bid_px_04', 'ask_px_04', 'bid_sz_04', 'ask_sz_04', \n",
    "    'bid_ct_04', 'ask_ct_04'\n",
    "]\n",
    "filtered_df = filtered_df[columns_to_keep]\n",
    "\n",
    "# Step 2: Calculate OFI\n",
    "def calculate_correct_ofi(df):\n",
    "    ofi_list = []\n",
    "    depth_levels = 5  # Levels 0 to 4\n",
    "    old_bid_sz = np.zeros(depth_levels)\n",
    "    old_ask_sz = np.zeros(depth_levels)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Store OFI for each depth level\n",
    "        ofi_event = {'ts_event': row['ts_event']}\n",
    "        total_ofi = 0\n",
    "        \n",
    "        for i in range(depth_levels):\n",
    "            # Extract current bid and ask sizes\n",
    "            new_bid_sz = row[f'bid_sz_0{i}']\n",
    "            new_ask_sz = row[f'ask_sz_0{i}']\n",
    "            \n",
    "            # Calculate delta sizes\n",
    "            delta_bid = new_bid_sz - old_bid_sz[i]\n",
    "            delta_ask = new_ask_sz - old_ask_sz[i]\n",
    "            \n",
    "            # Compute OFI for this level\n",
    "            level_ofi = delta_bid - delta_ask\n",
    "            ofi_event[f'ofi_0{i}'] = level_ofi\n",
    "            total_ofi += level_ofi\n",
    "            \n",
    "            # Update old sizes\n",
    "            old_bid_sz[i] = new_bid_sz\n",
    "            old_ask_sz[i] = new_ask_sz\n",
    "        \n",
    "        # Add total OFI for this event\n",
    "        ofi_event['total_ofi'] = total_ofi\n",
    "        ofi_list.append(ofi_event)\n",
    "\n",
    "    return pd.DataFrame(ofi_list)\n",
    "\n",
    "# Step 3: Apply Corrected OFI Calculation\n",
    "ofi_df = calculate_correct_ofi(filtered_df)\n",
    "\n",
    "# Step 4: Display Results\n",
    "#print(ofi_df.head())\n",
    "# Step 1: Extract OFI columns for PCA\n",
    "ofi_columns = [f'ofi_0{i}' for i in range(5)]  # Multi-level OFI columns\n",
    "ofi_data = ofi_df[ofi_columns]\n",
    "\n",
    "# Step 2: Standardize the OFI data\n",
    "scaler = StandardScaler()\n",
    "ofi_standardized = scaler.fit_transform(ofi_data)\n",
    "\n",
    "# Step 3: Apply PCA\n",
    "pca = PCA(n_components=1)  # Keep only the first principal component\n",
    "ofi_integrated = pca.fit_transform(ofi_standardized)\n",
    "\n",
    "# Step 4: Add the PCA result to the DataFrame\n",
    "ofi_df['ofi_integrated'] = ofi_integrated\n",
    "\n",
    "# Step 5: Display the updated DataFrame\n",
    "print(ofi_df[['ts_event', 'ofi_integrated']].head())\n",
    "\n",
    "# unique_levels = filtered_df['depth'].unique()\n",
    "\n",
    "# unique_levels_as_integers = [int(level) for level in unique_levels]\n",
    "\n",
    "# # Sort the levels\n",
    "# sorted_levels = sorted(unique_levels_as_integers)\n",
    "\n",
    "# print(\"Unique levels:\", sorted_levels)\n",
    "#display(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory_for_ofi(directory_path, levels=5):\n",
    "    \"\"\"\n",
    "    Process all .zst files in a directory to calculate multi-level OFI metrics and integrate them using PCA.\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing .zst files.\n",
    "        levels (int): Number of levels to calculate OFI for.\n",
    "    Returns:\n",
    "        DataFrame: Combined data with OFI metrics for all processed files.\n",
    "    \"\"\"\n",
    "    combined_data = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        # Check if the file ends with .zst\n",
    "        if file_name.endswith(\".zst\"):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "\n",
    "            try:\n",
    "                # Load the data from the .zst file\n",
    "                data = db.DBNStore.from_file(file_path)\n",
    "                df = data.to_df()\n",
    "\n",
    "                ofi_columns = []\n",
    "                # Step 1: Compute delta (changes) in bid and ask sizes for each level\n",
    "                for level in range(levels):  # Top levels: 0 to levels-1\n",
    "                    bid_px_col = f\"bid_px_0{level}\"\n",
    "                    ask_px_col = f\"ask_px_0{level}\"\n",
    "                    bid_sz_col = f\"bid_sz_0{level}\"\n",
    "                    ask_sz_col = f\"ask_sz_0{level}\"\n",
    "\n",
    "                    if not all(col in df.columns for col in [bid_px_col, ask_px_col, bid_sz_col, ask_sz_col]):\n",
    "                        print(f\"Missing columns for level {level} in file {file_name}, skipping level.\")\n",
    "                        continue\n",
    "\n",
    "                    ofi_bid_col = f\"ofi_bid_0{level}\"\n",
    "                    ofi_ask_col = f\"ofi_ask_0{level}\"\n",
    "\n",
    "                    # Calculate OFI using explicit numpy logic\n",
    "                    bid_diff = df[bid_sz_col].diff().fillna(0)\n",
    "                    ask_diff = df[ask_sz_col].diff().fillna(0)\n",
    "\n",
    "                    df[ofi_bid_col] = np.where(\n",
    "                        df[bid_px_col] >= df[bid_px_col].shift(), bid_diff, -df[bid_sz_col]\n",
    "                    )\n",
    "                    df[ofi_ask_col] = np.where(\n",
    "                        df[ask_px_col] <= df[ask_px_col].shift(), -ask_diff, df[ask_sz_col]\n",
    "                    )\n",
    "\n",
    "                    ofi_columns.extend([ofi_bid_col, ofi_ask_col])\n",
    "\n",
    "                # Step 2: Integrate Multi-Level OFI using PCA\n",
    "                print(\"Integrating multi-level OFI using PCA...\")\n",
    "                pca = PCA(n_components=1)\n",
    "                df[\"integrated_ofi\"] = pca.fit_transform(df[ofi_columns].fillna(0))\n",
    "\n",
    "                # Append processed data to combined list\n",
    "                combined_data.append(df)\n",
    "\n",
    "                print(\"OFI calculation completed for file.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    # Combine all processed data into a single DataFrame\n",
    "    if combined_data:\n",
    "        return pd.concat(combined_data, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No valid data processed.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "directory_path = \"../data/XNAS-20250103-FR8JNPNEEV\"  # Replace with your directory path\n",
    "levels = 5\n",
    "combined_ofi_data = process_directory_for_ofi(directory_path, levels)\n",
    "\n",
    "if not combined_ofi_data.empty:\n",
    "    print(\"Combined OFI Metrics (First 5 Rows):\")\n",
    "    print(combined_ofi_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
